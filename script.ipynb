{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Water Quality Prediction.csv')\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of 1000 rows\n",
    "df = df.sample(n=300000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                         0\n",
       "pH                         5890\n",
       "Iron                       2029\n",
       "Nitrate                    5355\n",
       "Chloride                   8814\n",
       "Lead                       1327\n",
       "Zinc                       8022\n",
       "Color                       292\n",
       "Turbidity                  2497\n",
       "Fluoride                   9599\n",
       "Copper                    10082\n",
       "Odor                       9006\n",
       "Sulfate                    9767\n",
       "Conductivity               8356\n",
       "Chlorine                   2862\n",
       "Manganese                  5409\n",
       "Total Dissolved Solids       88\n",
       "Source                     4411\n",
       "Water Temperature          8477\n",
       "Air Temperature            1464\n",
       "Month                      4767\n",
       "Day                        4951\n",
       "Time of Day                5814\n",
       "Potability                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows\n",
    "duplicate_rows = df[df.duplicated()]\n",
    "if duplicate_rows.count().sum() == 0:\n",
    "   print(\"No duplicate rows\")\n",
    "else:\n",
    "   print(\"Duplicate rows are present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove month and index columns\n",
    "df = df.drop(['Month', 'Index'], axis=1) # axis=1 indicates we are dropping a column, not a row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values in color and source columns\n",
    "df = df.dropna(subset=[\"Color\", \"Source\"])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# # Create a SimpleImputer and apply it to the numeric columns\n",
    "imputer = SimpleImputer(strategy='median')  # You can choose a different strategy if needed\n",
    "df[numeric_columns] = imputer.fit_transform(df[numeric_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need x, y values as numpy arrays\n",
    "X = df.iloc[:, 0:-1].values\n",
    "Y = df.iloc[:, -1].values\n",
    "\n",
    "# X = df.iloc[:, 1:-4].values\n",
    "# Y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.004799273, 6.13e-06, 7.114755278, 120.5277688, 4.62e-168,\n",
       "       1.564359234, 3, 0.613997908, 1.758450685, 0.255472008, 2.092090468,\n",
       "       120.745502, 241.4468855, 3.099393646, 0.044697746, 257.7175114, 3,\n",
       "       22.90091727, 54.31051792, 7.0, 6.0], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encode categorical values (1, 2, 3 ... values)\n",
    "le1 = LabelEncoder()\n",
    "X[:, 6] = le1.fit_transform(X[:, 6])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "X[:, 16] = le2.fit_transform(X[:, 16])\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, ..., 54.31051792, 7.0, 6.0],\n",
       "       [0.0, 1.0, 0.0, ..., 72.01686324, 6.0, 1.0],\n",
       "       [0.0, 0.0, 0.0, ..., 74.40050714, 6.0, 14.0],\n",
       "       ...,\n",
       "       [1.0, 0.0, 0.0, ..., 44.94757749, 16.0, 17.0],\n",
       "       [0.0, 0.0, 1.0, ..., 50.26662387, 3.0, 9.0],\n",
       "       [1.0, 0.0, 0.0, ..., 20.89056308, 16.0, 0.0]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Column transform categorical columns (0, 1, 0 ...)\n",
    "ct1 = ColumnTransformer(transformers=[('encode', OneHotEncoder(), [6])], remainder='passthrough')\n",
    "X = ct1.fit_transform(X)\n",
    "\n",
    "ct2 = ColumnTransformer(transformers=[('encode', OneHotEncoder(), [20])], remainder='passthrough')\n",
    "X = ct2.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 0.0, ..., 25.80560754, 4.0, 17.0],\n",
       "       [0.0, 0.0, 0.0, ..., 45.31816114, 16.0, 8.0],\n",
       "       [0.0, 0.0, 0.0, ..., 75.71125799, 16.0, 19.0],\n",
       "       ...,\n",
       "       [0.0, 0.0, 0.0, ..., 60.3323639, 19.0, 8.0],\n",
       "       [0.0, 0.0, 0.0, ..., 45.24376613, 21.0, 21.0],\n",
       "       [0.0, 0.0, 0.0, ..., 36.67733054, 1.0, 7.0]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X TRAIN [0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.08964742005388752\n",
      " 0.22250950554342272 0.15996135975192427 -0.6381875866222126\n",
      " -0.042288407823216426 -0.8072420424603828 0.06677454259727253\n",
      " 1.3226740845347544 -0.8490761665366783 0.9445235266694276\n",
      " -0.7634630583229903 -0.1073774995704066 -0.46782054283570396\n",
      " -0.20849567405751046 -1.018199837239626 -0.5522348960288287\n",
      " -1.8997789033146155 -1.3448568906243474 0.804588997837725]\n",
      "Y TRAIN [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Normalize input values\n",
    "\n",
    "sc = StandardScaler()  # range: -3 to +3\n",
    "x_train[:, 13:] = sc.fit_transform(x_train[:, 13:])\n",
    "x_test[:, 13:] = sc.transform(x_test[:, 13:])\n",
    "\n",
    "print(\"X TRAIN\", x_train[0])\n",
    "print(\"Y TRAIN\", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 1. 0. 0.]\n",
      "F1 Score: 0.7731525911708254\n",
      "Precision: 0.6480969380059329\n",
      "Recall: 0.9580081753994798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier = joblib.load('trained_RDF_model_3.joblib')\n",
    "\n",
    "y_pred_rdf = classifier.predict(x_test)\n",
    "print(y_pred_rdf)\n",
    "\n",
    "# Assuming y_true contains the true labels and y_pred contains the predicted labels\n",
    "precision = precision_score(y_test, y_pred_rdf)\n",
    "recall = recall_score(y_test, y_pred_rdf)\n",
    "f1 = f1_score(y_test, y_pred_rdf)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Logistic Regression classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_classifier = LogisticRegression(random_state=0)\n",
    "# lr_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(lr_classifier, 'trained_LR_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_lr = lr_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=2)\n",
    "# print(np.concatenate([y_pred_lr.reshape(len(y_pred_lr), 1), y_test.reshape(len(y_test), 1)], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confMatrix = confusion_matrix(y_test, y_pred_lr)\n",
    "# print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_model_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "# print(lr_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Support Vector Machine classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector classifier\n",
    "# svm_classifier = SVC(kernel='linear', random_state=0)  # default is rbf\n",
    "# svm_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(svm_classifier, 'trained_SVM_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_svm = svm_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confMatrix = confusion_matrix(y_test, y_pred_svm)\n",
    "# print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "# print(svm_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the K-Nearest Neighbour classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # classic euclidean distance\n",
    "# knn_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(knn_classifier, 'trained_KNN_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_knn = knn_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_model_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "# print(knn_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the decision tree classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# dtree_classifier = DecisionTreeClassifier(criterion='gini', random_state=0)\n",
    "# dtree_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(dtree_classifier, 'trained_DTR_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_dtree = dtree_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtc_model_accuracy = accuracy_score(y_test, y_pred_dtree)\n",
    "# print(dtc_model_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the random forest classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc_classifier = RandomForestClassifier(n_estimators = 100, criterion='entropy', random_state = 0)\n",
    "# rfc_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "# joblib.dump(rfc_classifier, 'trained_RDF_model_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_rdf = rfc_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_model_accuracy = accuracy_score(y_test, y_pred_rdf)\n",
    "# print(rfc_model_accuracy)\n",
    "\n",
    "# Accuracy\n",
    "\n",
    "# remove missing values - 0.8642686209991026\n",
    "# remove missing of categorical and replace others with median - 0.87615241140421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = [7.66857169, 7.06e-08, 7.541255359, 198.1312335, 1.31e-95,\n",
    "#        0.767179279, 'Colorless', 0.137766996, 1.008886456, 2.391833449,\n",
    "#        0.750761234, 148.9474344, 242.7039915, 3.709734571, 2.301398715,\n",
    "#        100.9851033, 'Stream', 9.674425593, 35.25315137, 12.0, 1.0]\n",
    "\n",
    "classifier = joblib.load('trained_RDF_model_3.joblib')\n",
    "values = [1, 7.06e-08, 7.541255359, 198.1312335, 1.31e-95,\n",
    "       0.767179279, 'Colorless', 0.137766996, 1.008886456, 2.391833449,\n",
    "       0.750761234, 148.9474344, 242.7039915, 3.709734571, 2.301398715,\n",
    "       100.9851033, 'Stream', 9.674425593, 35.25315137, 12.0, 1.0]\n",
    "\n",
    "# Convert the input values to a DataFrame\n",
    "input_data = pd.DataFrame([values])\n",
    "\n",
    "# Preprocess the input data\n",
    "input_data = input_data.values  # Convert to NumPy array\n",
    "\n",
    "# label encode the values\n",
    "input_data[:, 6] = le1.transform(input_data[:, 6])\n",
    "input_data[:, 16] = le2.transform(input_data[:, 16])\n",
    "\n",
    "# column transform the values\n",
    "input_data = ct1.transform(input_data)\n",
    "input_data = ct2.transform(input_data)\n",
    "\n",
    "# scale the values\n",
    "input_data[:, 13:] = sc.transform(input_data[:, 13:])\n",
    "\n",
    "# print(input_data)\n",
    "\n",
    "y_single = classifier.predict(input_data)\n",
    "\n",
    "print(y_single[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_single = rfc_classifier.predict(input_data)\n",
    "\n",
    "# print(y_single[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    classifier, x_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training Examples\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training Accuracy\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Test Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ACCURACY SCORES OF EACH MODEL\\n\")\n",
    "\n",
    "# print(\"Logistic Regression Classifier\\t\", round(lr_model_accuracy * 100, 2))\n",
    "# print(\"SVM Classifier\\t\\t\\t\", round(svm_model_accuracy * 100, 2))\n",
    "# print(\"K-NN Classifier\\t\\t\\t\", round(knn_model_accuracy * 100, 2))\n",
    "# print(\"Decision Tree Classifier\\t\", round(dtc_model_accuracy * 100, 2))\n",
    "# print(\"Random Forest Classifier\\t\", round(rfc_model_accuracy * 100, 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
